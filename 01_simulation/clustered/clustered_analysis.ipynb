{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial main simulation analysis\n",
    "\n",
    "- Performs the precursory analysis for the first set of main simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "from pycoalescence import CoalescenceTree\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# For dev use only - auto-reloading of modules\n",
    "%load_ext autoreload\n",
    "%aimport pycoalescence.coalescence_tree\n",
    "from pycoalescence.coalescence_tree import check_sql_table_exist\n",
    "from pycoalescence.helper import update_parameter_names\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = {'artinskian',\n",
    " 'asselian',\n",
    " 'bashkirian',\n",
    " 'gzhelian',\n",
    " 'kasimovian',\n",
    " 'kungurian',\n",
    " 'moscovian',\n",
    " 'sakmarian'}\n",
    "\n",
    "tetrapod_groups = {'amniote', 'amphibian'}\n",
    "max_density = OrderedDict(\n",
    "    {\n",
    "        (\"artinskian\", \"amniote\"): 15,\n",
    "        (\"artinskian\", \"amphibian\"): 15,\n",
    "        (\"asselian\", \"amniote\"): 6,\n",
    "        (\"asselian\", \"amphibian\"): 6,\n",
    "        (\"bashkirian\", \"amniote\"): 1,\n",
    "        (\"bashkirian\", \"amphibian\"): 23,\n",
    "        (\"gzhelian\", \"amniote\"): 7,\n",
    "        (\"gzhelian\", \"amphibian\"): 7,\n",
    "        (\"kasimovian\", \"amniote\"): 7,\n",
    "        (\"kasimovian\", \"amphibian\"): 4,\n",
    "        (\"kungurian\", \"amniote\"): 15,\n",
    "        (\"kungurian\", \"amphibian\"): 17,\n",
    "        (\"moscovian\", \"amniote\"): 4,\n",
    "        (\"moscovian\", \"amphibian\"): 21,\n",
    "        (\"sakmarian\", \"amniote\"): 6,\n",
    "        (\"sakmarian\", \"amphibian\"): 15,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_type_detection(fine_map_file):\n",
    "\t\"\"\"\n",
    "\tDetects the simulation type from the fine map path (because I didn't save it anywhere sensible!\n",
    "\t:param fine_map_file: the path to check for\n",
    "\t:return the sim type\n",
    "\t\"\"\"\n",
    "\tfor interval in intervals:\n",
    "\t\tfor tet_group in tetrapod_groups:\n",
    "\t\t\tif interval in fine_map_file and tet_group in fine_map_file:\n",
    "\t\t\t\treturn (interval, tet_group)\n",
    "\traise ValueError(\"No type detected! Filename: {}.\".format(fine_map_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the import directories and variables - paths relative to the jupyter notebook directory\n",
    "# fragmented=\"fragmented\" \n",
    "fragmented=\"clustered\" # put back if want to analyse normal sims\n",
    "local_dir = \"/home/sam/Documents/PhD/PaleoSampling\"\n",
    "ext_dir = \"/run/media/sam/Media/Paleo\"\n",
    "# local_dir = \"/Users/samthompson/Documents/PhD/PaleoSampling/\"\n",
    "# ext_dir = \"/Volumes/Seagate 3TB/Paleo/\"\n",
    "results_dir = os.path.join(ext_dir, \"Results\", \"PaleoMain\", \"Clustered1\")\n",
    "dst_folder = os.path.join(local_dir, \"Results\", \"Clustered1\")\n",
    "data_dir = os.path.join(ext_dir, \"Data\")\n",
    "speciation_rates = [0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete all simulations which haven't completed yet.\n",
    "for file in os.listdir(results_dir):\n",
    "\tif \".db\" in file:\n",
    "\t\ttry:\n",
    "\t\t\tt = CoalescenceTree(os.path.join(results_dir, file))\n",
    "\t\texcept IOError:\n",
    "\t\t\tprint(\"Removing incomplete simulation {}.\".format(file))\n",
    "\t\t\tos.remove(os.path.join(results_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the biodiversity metrics -  can take a bit of time\n",
    "for file in os.listdir(results_dir):\n",
    "    if \".db\" in file:\n",
    "        # print(file)\n",
    "        t = CoalescenceTree(os.path.join(results_dir, file))\n",
    "        if check_sql_table_exist(t.database, \"SPECIES_LIST_ORIGINAL\"):\n",
    "            t.revert_downsample()\n",
    "        t.wipe_data()\n",
    "        sim_params = t.get_simulation_parameters()\n",
    "        (interval, tet_group) = sim_type_detection(sim_params[\"sample_file\"])\n",
    "        deme = sim_params[\"deme\"]\n",
    "        sample_size = sim_params[\"sample_size\"]\n",
    "        downsample_rate = max_density[(interval, tet_group)] /( deme * sample_size)\n",
    "        (interval, tet_group) = sim_type_detection(sim_params[\"sample_file\"])\n",
    "        t.downsample(downsample_rate)\n",
    "        t.set_speciation_parameters(record_spatial=True,\n",
    "                                record_fragments=os.path.join(data_dir, \"configs\",\n",
    "                                                              \"fragments_{}_{}.csv\".format(interval, tet_group)),\n",
    "                                speciation_rates=speciation_rates)\n",
    "        t.clear_calculations()\n",
    "        t.apply()\n",
    "        t.import_comparison_data(os.path.join(data_dir, \"databases\", \"{}_{}.db\".format(interval, tet_group)))\n",
    "        # t.adjust_data()\n",
    "        t._clear_goodness_of_fit()\n",
    "        t.calculate_fragment_richness()\n",
    "        # t.calculate_alpha_diversity()\n",
    "        t.calculate_beta_diversity()\n",
    "        # break\n",
    "        t.calculate_goodness_of_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample from the simulations\n",
    "tmp = []\n",
    "distance_sim_tmp = []\n",
    "fragment_abundances = []\n",
    "for file in os.listdir(results_dir):\n",
    "\tif \".db\" in file:\n",
    "\t\t# print(file)\n",
    "\t\tt = CoalescenceTree(os.path.join(results_dir, file), logging_level=30)\n",
    "\t\tif check_sql_table_exist(t.database, \"SPECIES_DISTANCE_SIMILARITY\"):\n",
    "\t\t\tt.cursor.execute(\"DROP TABLE IF EXISTS SPECIES_DISTANCE_SIMILARITY\")\n",
    "\t\tt.calculate_species_distance_similarity()\n",
    "\t\tfor sr in speciation_rates:\n",
    "\t\t\t\tref = t.get_community_reference(speciation_rate=sr, time=0.0, fragments=True)\n",
    "\t\t\t\tspec_r = t.cursor.execute(\"SELECT actual FROM BIODIVERSITY_METRICS WHERE\"\n",
    "\t\t\t\t\t\t\t\t\t \" community_reference==? AND fragment=='whole' AND \"\n",
    "\t\t\t\t\t\t\t\t\t \"metric=='fragment_richness'\", \n",
    "\t\t\t\t\t\t\t\t\t (ref,)).fetchall()[0][0]\n",
    "\t\t\t\tb = t.cursor.execute(\"SELECT actual FROM BIODIVERSITY_METRICS WHERE\"\n",
    "\t\t\t\t\t\t\t\t\t \" community_reference==? AND fragment=='whole' AND \"\n",
    "\t\t\t\t\t\t\t\t\t \"metric=='beta_diversity'\", \n",
    "\t\t\t\t\t\t\t\t\t (ref,)).fetchall()[0][0]\n",
    "\t\t\t\ta = t.cursor.execute(\"SELECT actual FROM BIODIVERSITY_METRICS WHERE\"\n",
    "\t\t\t\t\t\t\t\t\t \" community_reference==? AND fragment=='whole' AND \"\n",
    "\t\t\t\t\t\t\t\t\t \"metric=='alpha_diversity'\", \n",
    "\t\t\t\t\t\t\t\t\t (ref,)).fetchall()[0][0]\n",
    "\t\t\t\tsim_params = t.get_simulation_parameters()\n",
    "\t\t\t\tspecies_richness = t.get_species_richness(ref)\n",
    "\t\t\t\tbeta = t.get_beta_diversity(ref)\n",
    "\t\t\t\talpha = t.get_alpha_diversity(ref)\n",
    "\t\t\t\tgoodness_fit = t.get_goodness_of_fit(reference=ref)\n",
    "\t\t\t\ttotal_ind = t.get_number_individuals(community_reference=ref)\n",
    "\t\t\t\t(interval, tet_group) = sim_type_detection(sim_params[\"sample_file\"])\n",
    "\t\t\t\tpc = 1.0#percent_cover_detection(sim_params[\"fine_map_file\"])\n",
    "\t\t\t\ttmp.append({\"interval\": interval, \"tetrapod_group\" : tet_group,\n",
    "\t\t\t\t\t\t\t\"sigma\" : sim_params[\"sigma\"], \"speciation_rate\" : sr,\n",
    "\t\t\t\t\t\t\t\"deme\" : sim_params[\"deme\"], \"richness\" : species_richness,\n",
    "\t\t\t\t\t\t\t\"beta_diversity\" : beta, \"alpha_diversity\" : alpha,\n",
    "\t\t\t\t\t\t   \t\"gof\" : goodness_fit, \"actual_richness\" : spec_r, \"actual_beta\" : b,\n",
    "\t\t\t\t\t\t\t\"actual_alpha\" : a, \"percent_cover\": pc, \"simulated_individuals\" : total_ind})\n",
    "\t\t\t\t# try:\n",
    "\t\t\t\tdistance_sim = t.get_species_distance_similarity(ref)\n",
    "\t\t\t\tfor distance, no_ind in distance_sim:\n",
    "\t\t\t\t\tdistance_sim_tmp.append({\"interval\": interval, \"tetrapod_group\" : tet_group,\n",
    "\t\t\t\t\t\t\t\t\t\t\t \"sigma\" : sim_params[\"sigma\"], \"speciation_rate\" : sr,\n",
    "\t\t\t\t\t\t\t\"deme\" : sim_params[\"deme\"], \"richness\" : species_richness,\n",
    "\t\t\t\t\t\t\t\"beta_diversity\" : beta, \"alpha_diversity\" : alpha,\n",
    "\t\t\t\t\t\t   \t\"gof\" : goodness_fit, \"actual_richness\" : spec_r, \"actual_beta\" : b,\n",
    "\t\t\t\t\t\t\t\"actual_alpha\" : a, \"distance\" : distance, \"no_individuals\" : no_ind,\"percent_cover\": pc})\n",
    "\t\t\t\tfor fragment in t.get_fragment_list(ref):\n",
    "\t\t\t\t\tr = t.get_fragment_richness(fragment, ref)\n",
    "\t\t\t\t\tfragment_abundances.append({\"interval\": interval, \"tetrapod_group\" : tet_group,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\"sigma\" : sim_params[\"sigma\"], \"speciation_rate\" : sr,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\"deme\" : sim_params[\"deme\"], \"richness\" : r,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\"fragment\" : fragment,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\"percent_cover\": pc})\n",
    "\t\t\t\t\n",
    "df = pd.DataFrame(tmp)\n",
    "df_distance_sim = pd.DataFrame(distance_sim_tmp)\n",
    "df_fragment_abundances = pd.DataFrame(fragment_abundances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output to csv\n",
    "src_csv = os.path.join(results_dir, \"results_{}.csv\".format(fragmented))\n",
    "df.to_csv(src_csv, index=False)\n",
    "src_csv2 = os.path.join(results_dir, \"results_distance_sim_{}.csv\".format(fragmented))\n",
    "df_distance_sim.to_csv(src_csv2)\n",
    "src_csv3 = os.path.join(results_dir, \"results_fragment_abundances_{}.csv\".format(fragmented))\n",
    "df_fragment_abundances.to_csv(src_csv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sam/Documents/PhD/PaleoSampling/Results/Clustered1/results_fragment_abundances_clustered.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the output csvs - change fragmented variable as appropriate\n",
    "if not os.path.exists(dst_folder):\n",
    "\tos.makedirs(dst_folder)\n",
    "dst_csv = os.path.join(dst_folder, \"results_{}.csv\".format(fragmented))\n",
    "dst_csv2 = os.path.join(dst_folder, \"results_distance_sim_{}.csv\".format(fragmented))\n",
    "dst_csv3 = os.path.join(dst_folder, \"results_fragment_abundances_{}.csv\".format(fragmented))\n",
    "shutil.copy2(src_csv, dst_csv)\n",
    "shutil.copy2(src_csv2, dst_csv2)\n",
    "shutil.copy2(src_csv3, dst_csv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clustered'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
